{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87363b4b",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>\n",
    "<img src=\"https://mma.prnewswire.com/media/1095203/East_Tennessee_State_University_Logo.jpg?p=facebook\" width=200 height=200 />\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h1 style=\"text-align: center\">CSCI 5037 - NLP & Text Analysis</h1>\n",
    "</div>\n",
    "\n",
    "# <center>Lab 2 - Text Cleaning </center>\n",
    "\n",
    "**<center>Dr. Ahmad Al-Doulat </center>**\n",
    "<center>Department of Computing </center>\n",
    "<center>East Tennessee State University</center>\n",
    "\n",
    "<hr style=\"border:2px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f647de7f",
   "metadata": {},
   "source": [
    "**In this assignment, you'll get to practice the concepts and skills covered in the first 2 modules (Modules 1&2). The main objective of this assignment is to implement and use some of the tools, algorithms, and techniques to represent and clean textual data..**\n",
    "\n",
    "\n",
    "\n",
    "**Guidelines**\n",
    "* Download `YelpReviews.csv` file from D2L. \n",
    "* Make sure to run all the code cells, otherwise you may get errors like `NameError` for undefined variables.\n",
    "* Do not change variable names, delete cells or disturb other existing code. It may cause problems during evaluation.\n",
    "* In some cases, you may need to add some code cells or new statements before or after the line of code containing the `???`.\n",
    "* Use markdown cells to write your discussions and reflections. \n",
    "\n",
    "**Procedure**\n",
    "* Save your work as `IPYNB` file named `Lab2.ipynb` and submit to D2L `Lab 2 - Text Cleaning (Dropbox)` by the due date.\n",
    "* As you go through this notebook, you will find the symbol `???` in certain places. To complete this assignment, you must replace all the `???` with appropriate values, expressions or statements to ensure that the notebook runs properly end-to-end.\n",
    "* Include your response for `Part 1` and `Part 2` in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e19a6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Part 1: Activity \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a1547",
   "metadata": {},
   "source": [
    "# Question 1: Reading the dataset \n",
    "<hr style=\"border:1px solid orange\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee93f4",
   "metadata": {},
   "source": [
    "#### Read the content of the `YelpReviews.csv` into a dataframe `reviews_df` and perform the following: \n",
    "\n",
    "> **Q1.1.** Merge all the contents of the `text` column in the `reviews_df`. Then, convert all contents to lower case and store the results in a string called `reviews`. **Note:** *Make sure to split the reviews using whitespaces*.   \n",
    "\n",
    "> **Q1.2.** Using regular expressions, remove numeric characters and special characters (characters that are not alphabetic or numeric characters) from the `reviews` variable and store the result in a variable called `alphabetic_reviews`.\n",
    "\n",
    "> **Q1.3.** Tokenize the `alphabetic_reviews` into individual words or individual tokens and store the result into a list called `reviews_words`. \n",
    "\n",
    "> **Q1.4.** Remove the stopwords from the `reviews_words` list and store the results into a list called `no_stops_reviews_words`.\n",
    "\n",
    "> **Q1.5.** Perform stemming on the words in `no_stops_reviews_words` and store the results into a list called `stemmed_words`. \n",
    "\n",
    "> **Q1.6.** Find the top `50` most common words from the `stemmed_words` and store them into a list called `top_50_stemmed_words`.\n",
    "\n",
    "> **Q1.7.** Perform lemmatizations on the words in `no_stops_reviews_words` and store the results into a list called `lemmatized_words`.\n",
    "\n",
    "> **Q1.8.** Find the top `50` most common words from the `lemmatized_words` and store them into a list called `top_50_lemmatized_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d45f8a-b9c5-4834-9e1a-af7166fae5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MAHARJANA\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b2f973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv('YelpReviews.csv')\n",
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33cbad6c-183e-4c5d-8152-d5c0430e8f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/26/2011</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/27/2011</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/14/2012</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/27/2010</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12/13/2007</td>\n",
       "      <td>m2CKSsepBCoRYWxiRUsxAg</td>\n",
       "      <td>4</td>\n",
       "      <td>Quiessence is, simply put, beautiful.  Full wi...</td>\n",
       "      <td>review</td>\n",
       "      <td>sqYN3lNgvPbPCTRsMFu27g</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2/12/2010</td>\n",
       "      <td>riFQ3vxNpP4rWLk_CSri2A</td>\n",
       "      <td>5</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "      <td>review</td>\n",
       "      <td>wFweIWhv2fREZV_dYkz_1g</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7/12/2012</td>\n",
       "      <td>JL7GXJ9u4YMx7Rzs05NfiQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Luckily, I didn't have to travel far to make m...</td>\n",
       "      <td>review</td>\n",
       "      <td>1ieuYcKS7zeAv_U15AB13A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8/17/2012</td>\n",
       "      <td>XtnfnYmnJYi71yIuGsXIUA</td>\n",
       "      <td>4</td>\n",
       "      <td>Definitely come for Happy hour! Prices are ama...</td>\n",
       "      <td>review</td>\n",
       "      <td>Vh_DlizgGhSqQh4qfZ2h6A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8/11/2010</td>\n",
       "      <td>jJAIXA46pU1swYyRCdfXtQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Nobuo shows his unique talents with everything...</td>\n",
       "      <td>review</td>\n",
       "      <td>sUNkXg8-KFtCMQDV6zRzQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date               review_id  stars  \\\n",
       "0   1/26/2011  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1   7/27/2011  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2   6/14/2012  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3   5/27/2010  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4    1/5/2012  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "5  12/13/2007  m2CKSsepBCoRYWxiRUsxAg      4   \n",
       "6   2/12/2010  riFQ3vxNpP4rWLk_CSri2A      5   \n",
       "7   7/12/2012  JL7GXJ9u4YMx7Rzs05NfiQ      4   \n",
       "8   8/17/2012  XtnfnYmnJYi71yIuGsXIUA      4   \n",
       "9   8/11/2010  jJAIXA46pU1swYyRCdfXtQ      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "5  Quiessence is, simply put, beautiful.  Full wi...  review   \n",
       "6  Drop what you're doing and drive here. After I...  review   \n",
       "7  Luckily, I didn't have to travel far to make m...  review   \n",
       "8  Definitely come for Happy hour! Prices are ama...  review   \n",
       "9  Nobuo shows his unique talents with everything...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
       "5  sqYN3lNgvPbPCTRsMFu27g     4       3      1  \n",
       "6  wFweIWhv2fREZV_dYkz_1g     7       7      4  \n",
       "7  1ieuYcKS7zeAv_U15AB13A     0       1      0  \n",
       "8  Vh_DlizgGhSqQh4qfZ2h6A     0       0      0  \n",
       "9  sUNkXg8-KFtCMQDV6zRzQg     0       1      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29779ddd-234d-4805-9bcd-cbf16be843a0",
   "metadata": {},
   "source": [
    "**Q1.1.** Merge all the contents of the `text` column in the `reviews_df`. Then, convert all contents to lower case and store the results in a string called `reviews`. **Note:** *Make sure to split the reviews using whitespaces*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49bfcea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my wife took me here on my birthday for breakfast and it was excellent. the weather was perfect which made sitting outside overlooking their grounds an absolute pleasure. our waitress was excellent and our food arrived quickly on the semi-busy saturday morning. it looked like the place fills up pretty quickly so the earlier you get here the better. do yourself a favor and get their bloody mary. it was phenomenal and simply the best i\\'ve ever had. i\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it. it was amazing. while everything on the menu looks excellent, i had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious. it came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete. it was the best \"toast\" i\\'ve ever had. anyway, i can\\'t wait to go back! i have no idea why some people give bad reviews about this place. it goes to show you, you can please everyone. they are probably griping about something that their own fault...there are many people like that. in any case, my friend and i arrived at about 5:50 pm this past sunday. it was pretty crowded, more than i thought for a sunday evening and thought we would have to wait forever to get a seat but they said we\\'ll be seated when the girl comes back from seating someone else. we were seated at 5:52 and the waiter came and got our drink orders. everyone was very pleasant from the host that seated us to the waiter to the server. the prices were very good as well. we placed our orders once we decided what we wanted at 6:02. we shared the baked spaghetti calzone and the small \"here\\'s the beef\" pizza so we can both try them. the calzone was huge and we got the smallest one (personal) and got the small 11\" pizza. both were awesome! my friend liked the pizza better and i liked the calzone better. the calzone does have a sweetish sauce but that\\'s how i like my sauce! we had to box part of the pizza to take it'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1.1. Merge all the contents of the text column in the reviews_df. \n",
    "# Then, convert all contents to lower case and store the results in a string called reviews. \n",
    "# Note: Make sure to split the reviews using whitespaces.\n",
    "\n",
    "reviews = \" \".join(reviews_df['text'].astype(str).str.lower().str.split().sum())\n",
    "reviews[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447cfba2-b434-437f-8b4b-0d02473cca4b",
   "metadata": {},
   "source": [
    "**Q1.2.** Using regular expressions, remove numeric characters and special characters (characters that are not alphabetic or numeric characters) from the `reviews` variable and store the result in a variable called `alphabetic_reviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14b1b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my wife took me here on my birthday for breakfast and it was excellent the weather was perfect which made sitting outside overlooking their grounds an absolute pleasure our waitress was excellent and our food arrived quickly on the semibusy saturday morning it looked like the place fills up pretty quickly so the earlier you get here the better do yourself a favor and get their bloody mary it was phenomenal and simply the best ive ever had im pretty sure they only use ingredients from their garden and blend them fresh when you order it it was amazing while everything on the menu looks excellent i had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious it came with  pieces of their griddled bread with was amazing and it absolutely made the meal complete it was the best toast ive ever had anyway i cant wait to go back i have no idea why some people give bad reviews about this place it goes to show you you can please everyone they are probably griping about something that their own faultthere are many people like that in any case my friend and i arrived at about  pm this past sunday it was pretty crowded more than i thought for a sunday evening and thought we would have to wait forever to get a seat but they said well be seated when the girl comes back from seating someone else we were seated at  and the waiter came and got our drink orders everyone was very pleasant from the host that seated us to the waiter to the server the prices were very good as well we placed our orders once we decided what we wanted at  we shared the baked spaghetti calzone and the small heres the beef pizza so we can both try them the calzone was huge and we got the smallest one personal and got the small  pizza both were awesome my friend liked the pizza better and i liked the calzone better the calzone does have a sweetish sauce but thats how i like my sauce we had to box part of the pizza to take it home and we were out the door by  so everything was great and n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1.2. Using regular expressions, remove numeric characters and \n",
    "# special characters (characters that are not alphabetic or numeric characters) \n",
    "# from the reviews variable and store the result in a variable called alphabetic_reviews.\n",
    "\n",
    "def apply_regex(text):\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove special characters (characters that are not alphabetic or numeric characters)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "alphabetic_reviews = apply_regex(reviews)\n",
    "alphabetic_reviews[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3cc6c-f9ea-4696-bdff-440d29ccc8fa",
   "metadata": {},
   "source": [
    "**Q1.3.** Tokenize the `alphabetic_reviews` into individual words or individual tokens and store the result into a list called `reviews_words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7912222b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'wife',\n",
       " 'took',\n",
       " 'me',\n",
       " 'here',\n",
       " 'on',\n",
       " 'my',\n",
       " 'birthday',\n",
       " 'for',\n",
       " 'breakfast',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'excellent',\n",
       " 'the',\n",
       " 'weather',\n",
       " 'was',\n",
       " 'perfect',\n",
       " 'which',\n",
       " 'made',\n",
       " 'sitting',\n",
       " 'outside',\n",
       " 'overlooking',\n",
       " 'their',\n",
       " 'grounds',\n",
       " 'an',\n",
       " 'absolute',\n",
       " 'pleasure',\n",
       " 'our',\n",
       " 'waitress',\n",
       " 'was',\n",
       " 'excellent',\n",
       " 'and',\n",
       " 'our',\n",
       " 'food',\n",
       " 'arrived',\n",
       " 'quickly',\n",
       " 'on',\n",
       " 'the',\n",
       " 'semibusy',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " 'it',\n",
       " 'looked',\n",
       " 'like',\n",
       " 'the',\n",
       " 'place',\n",
       " 'fills',\n",
       " 'up',\n",
       " 'pretty']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1.3. Tokenize the alphabetic_reviews into individual words or individual tokens\n",
    "# and store the result into a list called reviews_words.\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "reviews_words = tokenize_text(alphabetic_reviews)\n",
    "reviews_words[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c87fc3-80a0-43c1-be26-a6ad4211d896",
   "metadata": {},
   "source": [
    "**Q1.4.** Remove the stopwords from the `reviews_words` list and store the results into a list called `no_stops_reviews_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e631036e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wife',\n",
       " 'took',\n",
       " 'birthday',\n",
       " 'breakfast',\n",
       " 'excellent',\n",
       " 'weather',\n",
       " 'perfect',\n",
       " 'made',\n",
       " 'sitting',\n",
       " 'outside',\n",
       " 'overlooking',\n",
       " 'grounds',\n",
       " 'absolute',\n",
       " 'pleasure',\n",
       " 'waitress',\n",
       " 'excellent',\n",
       " 'food',\n",
       " 'arrived',\n",
       " 'quickly',\n",
       " 'semibusy',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " 'looked',\n",
       " 'like',\n",
       " 'place',\n",
       " 'fills',\n",
       " 'pretty',\n",
       " 'quickly',\n",
       " 'earlier',\n",
       " 'get',\n",
       " 'better',\n",
       " 'favor',\n",
       " 'get',\n",
       " 'bloody',\n",
       " 'mary',\n",
       " 'phenomenal',\n",
       " 'simply',\n",
       " 'best',\n",
       " 'ive',\n",
       " 'ever',\n",
       " 'im',\n",
       " 'pretty',\n",
       " 'sure',\n",
       " 'use',\n",
       " 'ingredients',\n",
       " 'garden',\n",
       " 'blend',\n",
       " 'fresh',\n",
       " 'order',\n",
       " 'amazing']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1.4. Remove the stopwords from the reviews_words list \n",
    "# and store the results into a list called no_stops_reviews_words.\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "no_stops_reviews_words = remove_stopwords(reviews_words)\n",
    "no_stops_reviews_words[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970990b0-34f8-4007-967d-a846445e46a2",
   "metadata": {},
   "source": [
    "**Q1.5.** Perform stemming on the words in `no_stops_reviews_words` and store the results into a list called `stemmed_words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e00e62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wife',\n",
       " 'took',\n",
       " 'birthday',\n",
       " 'breakfast',\n",
       " 'excel',\n",
       " 'weather',\n",
       " 'perfect',\n",
       " 'made',\n",
       " 'sit',\n",
       " 'outsid',\n",
       " 'overlook',\n",
       " 'ground',\n",
       " 'absolut',\n",
       " 'pleasur',\n",
       " 'waitress',\n",
       " 'excel',\n",
       " 'food',\n",
       " 'arriv',\n",
       " 'quickli',\n",
       " 'semibusi',\n",
       " 'saturday',\n",
       " 'morn',\n",
       " 'look',\n",
       " 'like',\n",
       " 'place',\n",
       " 'fill',\n",
       " 'pretti',\n",
       " 'quickli',\n",
       " 'earlier',\n",
       " 'get',\n",
       " 'better',\n",
       " 'favor',\n",
       " 'get',\n",
       " 'bloodi',\n",
       " 'mari',\n",
       " 'phenomen',\n",
       " 'simpli',\n",
       " 'best',\n",
       " 'ive',\n",
       " 'ever',\n",
       " 'im',\n",
       " 'pretti',\n",
       " 'sure',\n",
       " 'use',\n",
       " 'ingredi',\n",
       " 'garden',\n",
       " 'blend',\n",
       " 'fresh',\n",
       " 'order',\n",
       " 'amaz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1.5. Perform stemming on the words in no_stops_reviews_words \n",
    "# and store the results into a list called stemmed_words.\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def normalize_text_stemmer(tokens):\n",
    "    # Stemming\n",
    "    stemmed = [stemmer.stem(word) for word in tokens]\n",
    "    return stemmed\n",
    "\n",
    "stemmed_words = normalize_text_stemmer(no_stops_reviews_words)\n",
    "stemmed_words[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9117a5be-20f4-42e1-b317-d4c47d5e2404",
   "metadata": {},
   "source": [
    "**Q1.6.** Find the top `50` most common words from the `stemmed_words` and store them into a list called `top_50_stemmed_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a63d7e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('place', 7462), ('good', 6871), ('food', 6261), ('like', 5609), ('great', 5083), ('go', 4868), ('get', 4652), ('time', 4586), ('one', 4268), ('order', 3653), ('realli', 3348), ('servic', 3191), ('would', 3063), ('love', 3043), ('tri', 2914), ('back', 2884), ('dont', 2604), ('also', 2508), ('make', 2315), ('nice', 2310), ('even', 2270), ('im', 2263), ('littl', 2217), ('well', 2186), ('restaur', 2177), ('look', 2163), ('want', 2126), ('ive', 2110), ('come', 2066), ('price', 2053), ('alway', 2016), ('best', 1939), ('us', 1909), ('got', 1901), ('thing', 1806), ('pretti', 1804), ('drink', 1799), ('know', 1777), ('menu', 1755), ('wait', 1755), ('much', 1749), ('chicken', 1727), ('think', 1725), ('eat', 1694), ('bar', 1670), ('peopl', 1667), ('didnt', 1646), ('say', 1636), ('first', 1621), ('night', 1578)]\n"
     ]
    }
   ],
   "source": [
    "# Q1.6. Find the top 50 most common words from the stemmed_words \n",
    "# and store them into a list called top_50_stemmed_words.\n",
    "\n",
    "top_50_stemmed_words = Counter(stemmed_words)\n",
    "print(top_50_stemmed_words.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14d285-a285-4dce-a498-66149bd8ec80",
   "metadata": {},
   "source": [
    "**Q1.7.** Perform lemmatizations on the words in `no_stops_reviews_words` and store the results into a list called `lemmatized_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc84dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wife',\n",
       " 'took',\n",
       " 'birthday',\n",
       " 'breakfast',\n",
       " 'excellent',\n",
       " 'weather',\n",
       " 'perfect',\n",
       " 'made',\n",
       " 'sitting',\n",
       " 'outside',\n",
       " 'overlooking',\n",
       " 'ground',\n",
       " 'absolute',\n",
       " 'pleasure',\n",
       " 'waitress',\n",
       " 'excellent',\n",
       " 'food',\n",
       " 'arrived',\n",
       " 'quickly',\n",
       " 'semibusy',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " 'looked',\n",
       " 'like',\n",
       " 'place',\n",
       " 'fill',\n",
       " 'pretty',\n",
       " 'quickly',\n",
       " 'earlier',\n",
       " 'get',\n",
       " 'better',\n",
       " 'favor',\n",
       " 'get',\n",
       " 'bloody',\n",
       " 'mary',\n",
       " 'phenomenal',\n",
       " 'simply',\n",
       " 'best',\n",
       " 'ive',\n",
       " 'ever',\n",
       " 'im',\n",
       " 'pretty',\n",
       " 'sure',\n",
       " 'use',\n",
       " 'ingredient',\n",
       " 'garden',\n",
       " 'blend',\n",
       " 'fresh',\n",
       " 'order',\n",
       " 'amazing']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1.7. Perform lemmatizations on the words in no_stops_reviews_words \n",
    "# and store the results into a list called lemmatized_words.\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def normalize_text_lemmatizer(tokens):\n",
    "    # Lemmatization\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return lemmatized\n",
    "\n",
    "lemmatized_words = normalize_text_lemmatizer(no_stops_reviews_words)\n",
    "lemmatized_words[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65401a62-873b-476c-a046-110d41a56321",
   "metadata": {},
   "source": [
    "**Q1.8.** Find the top `50` most common words from the `lemmatized_words` and store them into a list called `top_50_lemmatized_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6282220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('place', 7370), ('good', 6768), ('food', 6261), ('great', 5069), ('like', 5039), ('time', 4534), ('one', 4267), ('get', 4118), ('go', 3620), ('really', 3348), ('service', 3180), ('would', 3063), ('back', 2868), ('dont', 2603), ('also', 2508), ('love', 2355), ('im', 2263), ('little', 2217), ('nice', 2207), ('well', 2177), ('restaurant', 2177), ('ive', 2110), ('make', 2018), ('always', 2013), ('even', 1997), ('best', 1939), ('u', 1939), ('got', 1900), ('thing', 1806), ('pretty', 1804), ('menu', 1755), ('much', 1749), ('try', 1738), ('chicken', 1727), ('order', 1726), ('know', 1715), ('ordered', 1703), ('price', 1682), ('bar', 1669), ('people', 1667), ('drink', 1666), ('come', 1651), ('didnt', 1646), ('first', 1621), ('night', 1578), ('think', 1571), ('could', 1539), ('never', 1530), ('better', 1529), ('went', 1510)]\n"
     ]
    }
   ],
   "source": [
    "# Q1.8. Find the top 50 most common words from the lemmatized_words \n",
    "# and store them into a list called top_50_lemmatized_words.\n",
    "\n",
    "top_50_lemmatized_words = Counter(lemmatized_words)\n",
    "print(top_50_lemmatized_words.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c4859",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Part 2: Reflection\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f41c86",
   "metadata": {},
   "source": [
    "As a second stepâ€”after answering the questions, include the following:\n",
    "1. A reflection of your experience performing the activity. \n",
    "2. A reflection on the importance of learning this activity.\n",
    "**Note:** include your reflection in this notebook as markdown cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04ec951",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "1. This lab activity has been one of the easiest lab activities for me so far (counting all the ML lab activities and the first lab activity of NLP & Text Analysis). All the concepts required for this lab were almost familiar beforehand. The lecture class further helped clarify all the topics as it included examples. The only new concept here was the normalization of data through Stemming and Lemmatization, which was clearly explained in the lecture slides and examples.\n",
    "2. As we have studied, a poor model with a good dataset performs far better than a good model with a poor dataset. This signifies how important the dataset is. Datasets are always noisy, and the first step is to clean them. Thus, data preprocessing is ultimately a vital step. In ML classes, too, we performed data cleaning before fitting the data into the model in every lab. Therefore, the concepts we have learned in this lab will be helpful for all future labs and projects, as well as for real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c3dbe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Submission\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd22e1a",
   "metadata": {},
   "source": [
    "Submit **Lab2.ipynb** to the **Lab 2 - Text Cleaning (Dropbox)** on D2L by the due date. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053c344",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Grading Rubric\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c85704",
   "metadata": {},
   "source": [
    "|Criterion\t|Excellent\t|Good\t|Average\t|Below Average\t|Poor\t|No Attempt|\n",
    "|:--\t|:--\t|:--\t|:--\t|:-- \t|:--\t|:-- |\n",
    "|**Part 1:** Activity-Question 1.1|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.2|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.3|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.4|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.5|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.6|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.7|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.8|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 2:** Reflection|**10 points**- Reflection clearly ties to the module content; experience and importance clearly laid out|**8 points**- Reflection mostly ties to the module content; experience & importance are discussed|**6 points**- Reflection ties minimally to the module content; experience & importance are discussed but not thoroughly|**4 points**- Reflection does not tie to the module content; experience & importance are minimally discussed|**2 points**- Minimal effort to tie to content; minimal effort to describe experience/ importance|**0 points**- Did not complete the reflection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214.052px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
